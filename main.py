import openai
import subprocess
import os
import random
import time
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
load_dotenv()

# OpenAI APIã‚­ãƒ¼ã‚’å–å¾—
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("ç’°å¢ƒå¤‰æ•° 'OPENAI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
client = openai.OpenAI(api_key=api_key)

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
output_file = "C:\\Users\\koshi\\Work\\PromptMotion\\output.mp3"
temp_dir = "C:\\Users\\koshi\\Work\\PromptMotion\\temp"
instructions_file = "C:\\Users\\koshi\\Work\\PromptMotion\\instructions.txt"
dancers_file = "C:\\Users\\koshi\\Work\\PromptMotion\\dancers.txt"

# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
if not os.path.exists(temp_dir):
    os.makedirs(temp_dir)

def load_instructions(file_path):
    """ æŒ‡ç¤ºãƒªã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æŒ‡ç¤ºã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")

    with open(file_path, "r", encoding="utf-8") as file:
        instructions = [line.strip() for line in file.readlines() if line.strip()]

    return instructions

def load_dancers(file_path):
    """ ãƒ€ãƒ³ã‚µãƒ¼ä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€ """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"ãƒ€ãƒ³ã‚µãƒ¼ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")

    with open(file_path, "r", encoding="utf-8") as file:
        dancers = [line.strip() for line in file.readlines() if line.strip()]

    if not dancers:
        raise ValueError("ãƒ€ãƒ³ã‚µãƒ¼ã®ãƒªã‚¹ãƒˆãŒç©ºã§ã™ã€‚")

    return dancers

def generate_random_instruction():
    """ AIã«ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ€ãƒ³ã‚¹ã®æŒ‡ç¤ºã‚’ç”Ÿæˆã•ã›ã‚‹ """
    prompt = """ã‚ãªãŸã¯ãƒ€ãƒ³ã‚¹ã®æŒ‡å°è€…ã§ã™ã€‚
    1ã¤ã®ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ€ãƒ³ã‚¹ã®æŒ‡ç¤ºã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    - å…·ä½“çš„ã§æ˜ç¢ºãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    - ä¾‹: ã€Œå³æ‰‹ã‚’ä¸Šã’ã‚‹ã€ã€Œå·¦è¶³ã‚’ä¸€æ­©å‰ã«å‡ºã™ã€
    1ã¤ã ã‘å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    """

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": prompt}]
    )

    return response.choices[0].message.content.strip()

def process_instructions_with_timing(instructions, dancers):
    """ æŒ‡ç¤ºã®é–“éš”ã‚’æŒ‡å®šã•ã‚ŒãŸç§’æ•°ã§èª¿æ•´ã—ã€æŒ‡å®šãŒãªã„å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ ã«è¨­å®š """
    processed_instructions = []
    silence_durations = []

    for instruction in instructions:
        parts = instruction.split(",")  # ã‚«ãƒ³ãƒã§åˆ†å‰²
        action_part = parts[0].strip()  # æŒ‡ç¤ºéƒ¨åˆ†
        time_part = parts[1].strip() if len(parts) > 1 else None  # ç§’æ•°éƒ¨åˆ†

        # **Anyone** ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ€ãƒ³ã‚µãƒ¼ã«ç½®ãæ›ãˆã‚‹
        if "**Anyone**" in action_part:
            dancer = random.choice(dancers)
            action_part = action_part.replace("**Anyone**", dancer)

        # **randomize** ã‚’AIç”Ÿæˆã«å¤‰æ›´
        if "**randomize**" in action_part:
            dancer = action_part.split(" ")[0]  # ãƒ€ãƒ³ã‚µãƒ¼åã‚’å–å¾—
            random_instruction = generate_random_instruction()
            processed_instructions.append(f"{dancer} {random_instruction}")
        else:
            processed_instructions.append(action_part)

        # æŒ‡å®šã•ã‚ŒãŸç§’æ•°ã®ç„¡éŸ³ or ãƒ©ãƒ³ãƒ€ãƒ 
        silence_durations.append(int(time_part[:-1]) if time_part and time_part.endswith("s") and time_part[:-1].isdigit() else random.randint(2, 10))

    return processed_instructions, silence_durations

def create_silent_audio(duration):
    """ æŒ‡å®šã—ãŸç§’æ•°ã®ç„¡éŸ³mp3ã‚’ä½œæˆï¼ˆæ—¢å­˜ã®ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†åˆ©ç”¨ï¼‰ """
    silence_file = f"{temp_dir}\\silence_{duration}.mp3"

    # æ—¢ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å†ä½œæˆã—ãªã„
    if os.path.exists(silence_file):
        print(f"[INFO] æ—¢å­˜ã®ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†åˆ©ç”¨: {silence_file}")
        return silence_file

    print(f"[INFO] ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­: {silence_file} ({duration}s)")
    command = f'ffmpeg -y -f lavfi -i anullsrc=r=24000:cl=mono -t {duration} -q:a 9 -acodec libmp3lame "{silence_file}"'
    subprocess.run(command, shell=True)

    return silence_file

def run_command_with_retry(command, max_retries=3, delay=5):
    """ ã‚³ãƒãƒ³ãƒ‰ã‚’æœ€å¤§ max_retries å›ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ """
    for attempt in range(max_retries):
        try:
            subprocess.run(command, shell=True, check=True)
            return True
        except subprocess.CalledProcessError as e:
            print(f"[ERROR] ã‚³ãƒãƒ³ãƒ‰å¤±æ•— ({attempt+1}/{max_retries}): {e}")
            time.sleep(delay)
    return False

def speak_text_with_custom_silence(texts, silence_durations):
    """ æŒ‡ç¤ºã”ã¨ã«æŒ‡å®šã•ã‚ŒãŸç§’æ•°ã¾ãŸã¯ãƒ©ãƒ³ãƒ€ãƒ ãªç„¡éŸ³ã‚’æŒ¿å…¥ã—ãªãŒã‚‰ mp3 ã‚’ä½œæˆï¼ˆé€²æ—è¡¨ç¤ºã‚ã‚Šï¼‰ """
    temp_files = []
    total_steps = len(texts)

    for i, (text, silence_duration) in enumerate(zip(texts, silence_durations)):
        parts = text.split(" ", 1)
        if len(parts) < 2:
            continue

        dancer_name = parts[0]
        instruction = parts[1]

        temp_dancer_file = f"{temp_dir}\\dancer_{i}.mp3"
        temp_instruction_file = f"{temp_dir}\\instruction_{i}.mp3"

        temp_files.append(temp_dancer_file)
        temp_files.append(temp_instruction_file)

        # é€²æ—è¡¨ç¤º
        print(f"[INFO] ({i+1}/{total_steps}) {dancer_name}: {instruction}")

        # ãƒ€ãƒ³ã‚µãƒ¼åã®éŸ³å£°ç”Ÿæˆ
        command_dancer = f'edge-tts --text "{dancer_name}" --voice ja-JP-NanamiNeural --rate=+5% --volume=+0% --write-media "{temp_dancer_file}"'
        if not run_command_with_retry(command_dancer):
            print(f"[ERROR] {dancer_name} ã®éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            continue  

        # æŒ‡ç¤ºæ–‡ã®éŸ³å£°ç”Ÿæˆ
        command_instruction = f'edge-tts --text "{instruction}" --voice ja-JP-NanamiNeural --rate=+5% --volume=+0% --write-media "{temp_instruction_file}"'
        if not run_command_with_retry(command_instruction):
            print(f"[ERROR] {instruction} ã®éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            continue  

        # ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ï¼ˆæ—¢å­˜ã®ã‚‚ã®ãŒã‚ã‚Œã°å†åˆ©ç”¨ï¼‰
        silence_file = create_silent_audio(silence_duration)
        temp_files.append(silence_file)

    # ã™ã¹ã¦ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
    concat_list = "|".join(temp_files)
    merge_command = f'ffmpeg -y -i "concat:{concat_list}" -acodec copy "{output_file}"'
    subprocess.run(merge_command, shell=True)

    # Windowsã®ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§å†ç”Ÿ
    subprocess.Popen(["start", "", output_file], shell=True)

    print("[INFO] ã™ã¹ã¦ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†å®Œäº†ã—ã¾ã—ãŸï¼")

    """ æŒ‡ç¤ºã”ã¨ã«æŒ‡å®šã•ã‚ŒãŸç§’æ•°ã¾ãŸã¯ãƒ©ãƒ³ãƒ€ãƒ ãªç„¡éŸ³ã‚’æŒ¿å…¥ã—ãªãŒã‚‰ mp3 ã‚’ä½œæˆ """
    temp_files = []

    for i, (text, silence_duration) in enumerate(zip(texts, silence_durations)):
        parts = text.split(" ", 1)
        if len(parts) < 2:
            continue

        dancer_name = parts[0]
        instruction = parts[1]

        temp_dancer_file = f"{temp_dir}\\dancer_{i}.mp3"
        temp_instruction_file = f"{temp_dir}\\instruction_{i}.mp3"

        temp_files.append(temp_dancer_file)
        temp_files.append(temp_instruction_file)

        # ãƒ€ãƒ³ã‚µãƒ¼åã®éŸ³å£°ç”Ÿæˆ
        command_dancer = f'edge-tts --text "{dancer_name}" --voice ja-JP-NanamiNeural --rate=+5% --volume=+0% --write-media "{temp_dancer_file}"'
        if not run_command_with_retry(command_dancer):
            print(f"[ERROR] {dancer_name} ã®éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            continue  

        # æŒ‡ç¤ºæ–‡ã®éŸ³å£°ç”Ÿæˆ
        command_instruction = f'edge-tts --text "{instruction}" --voice ja-JP-NanamiNeural --rate=+5% --volume=+0% --write-media "{temp_instruction_file}"'
        if not run_command_with_retry(command_instruction):
            print(f"[ERROR] {instruction} ã®éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            continue  

        # ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ï¼ˆæ—¢å­˜ã®ã‚‚ã®ãŒã‚ã‚Œã°å†åˆ©ç”¨ï¼‰
        silence_file = create_silent_audio(silence_duration)
        temp_files.append(silence_file)

    # ã™ã¹ã¦ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
    concat_list = "|".join(temp_files)
    merge_command = f'ffmpeg -y -i "concat:{concat_list}" -acodec copy "{output_file}"'
    subprocess.run(merge_command, shell=True)

    # Windowsã®ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§å†ç”Ÿ
    subprocess.Popen(["start", "", output_file], shell=True)

if __name__ == "__main__":
    raw_instructions = load_instructions(instructions_file)
    dancers = load_dancers(dancers_file)
    final_instructions, silence_durations = process_instructions_with_timing(raw_instructions, dancers)
    print("\nğŸ¤ ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã§æŒ‡ç¤ºã‚’èª­ã¿ä¸Šã’ã¾ã™...")
    speak_text_with_custom_silence(final_instructions, silence_durations)
